# Algoritmos de tragamonedas (bandits)

En esta sección consideramos el problema de hacer cambios
en un sitio web, por ejemplo, con el fin de mejorar métricas
como conversiones, ventas, tráfico, tasas de click-through, etc.


## Causalidad y contrafactuales

Para entender por qué este problema no es trivial, consideremos
que alguien estamos considerenda hacer una modificación del algoritmo de búsquedas de una tienda online. Por ejemplo: quizá estamos pensando
en usar un nuevo algoritmo para ordenar los resultados de una búsqueda
en la tienda.

En algunos casos es claro que nuestro cambio representa una mejora (por ejemplo, cuando arreglamos un *bug*), pero muchas veces no estamos muy
seguros de que el cambio vaya a ser beneficioso. En este ejemplo,
podriamos tomar como métrica de interés el número de conversiones: cuántas de las búsquedas terminan en acciones positivas (compras, añadir a canasta, etc.)

Una primera aproximación es hacer el cambio, y observar las métricas de interés. Sin embargo, los números resultantes **pueden ser difíciles de interpretar**: por ejemplo, si hicimos el cambio justo antes de navidad, es
normal esperar más compras resultantes de las búsquedas, pues en promedio
la gente que llega está más decidida a comprar que en otros periodos.
Esto no quiere decir que nuestro cambio fue positivo, pues quizá las 
ventas hubieran sido aún mayores si no hubiérmos hecho el cambio.

Otra aproximación simplista en los negocios es comparar *year over year*, por ejemplo, comparamos esta navidad con las anteriores. Esto también da un
resultado difícil de interpretar, pues estamos comparados dos periodos
alejados en el tiempo.

```{block2, type="resumen"}
Desde el punto de vista conceptual, lo que quisiéramos saber es *cómo
nos hubiera ido* si no hubiéramos hecho el cambio. Si supiéramos este
resultado, podríamos comparar directamente y evaluar el efecto de nuestro
cambio. A este escenario típicamente no observado le llamamos **contrafactual**, y es útil para razonar en este tipo de problemas.
```

#### Ejemplo {-}

En este ejemplo consideramos un escenario posible (simulado)
```{r, message=FALSE, warning = FALSE}
if(!require(CausalImpact)){
  install.packages("CausalImpact")
}
library(CausalImpact)
library(tidyverse)
set.seed(4)
x1 <- 100 + arima.sim(model = list(ar = 0.999), n = 100)
y <- 1.2 * x1 + rnorm(100) # ventas simuladas
y[71:100] <- y[71:100] + 7 # efecto de la intervención en el periodo 70.
time.points <- seq.Date(as.Date("2014-01-01"), by = 1, length.out = 100)
data <- zoo(cbind(y, x1), time.points)
pre.period <- as.Date(c("2014-01-01", "2014-03-11"))
post.period <- as.Date(c("2014-03-12", "2014-04-10"))
impact <- CausalImpact(data, pre.period, post.period)
plot(impact, metrics="original")
```


La línea sólida son las ventas observadas (diarias). La línea vertical señala
cuando se hizo la intervención. La línea punteada es el contrafactual estimado: cuáles hubieran sido las ventas si no hubiéramos hecho la intervención. Nótese que un análisis superficial que sólo considera las ventas observadas podría concluir que la intervención no tuvo efecto, pero en realidad la situación es muy diferente: la intervención sostuvo las ventas durante el mes analizado.



- Este análisis se basa en la construcción de **contrafactuales** con modelos dinámicos bayesianos. La idea es simple: supongamos que nuestra métrica de interés es $y$. Enconcontramos una covariable $x_1$, y construimos un modelo
(con los datos anteriores a la intervención) para $y$ con $x_1$ como covariable. La covariable $x_1$ debe ser escogida de forma que **tengamos evidencia fuerta** de que esta variable **no será afectada por la intervención**. De este forma, el contrafactual después de la intervención se construye haciendo la predicción de $y$ basada en $x_1$, y nos da una idea de lo que hubiera pasado sin la intervención.

- Por ejemplo, en algunos casos podemos escoger $x_1$ como las ventas de la región A, $y$ son la ventas de la región $B$. Nuestra intervención (por ejemplo, una promoción) la aplicamos solamente en la región $y$. Entonces el modelo basado en $x_1$ nos da el contrafactual para comparar.

Estas ideas son de el 
método propuesto en [CausalImpact](https://github.com/google/CausalImpact), 
[@causalimpact]. Es una versión más sofisticada y poderosa del método de diferencia de diferencias.

## Experimentos A/B

Cuando consideramos cambios a un servicio web, y queremos entender el 
efecto en los usuarios, podemos considerar otra estrategia para 
estimar el efecto de nuestras intervenciones.

Considerando que tenemos un número relativamente grande de visitas,
podemos hacer un **experimento A/B*:
seleccionamos al azar un subconjunto de usuarios para mostrarles
el sitio **con** la intervención (grupo B), y al resto les mostramos
el sitio **sin** la intervención (grupo A). Como seleccionamos al azar
los usuarios, las poblaciones son comparables en cuanto a demográficos y
tipos de usuarios, y no tenemos problemas de hacer comparaciones fuera de temporalidad. Comparamos los resultados de los dos grupos
para evaluar el efecto de la intervención.

Nótese que esta estrategia puede no funcionar bien si usamos una asignación
a grupos que no es aleatoria. Un ejemplo típico es considerar el efecto
de un anuncio de *paid search*. Podemos comparar usuarios que recibieron
el anuncio con otros que no lo recibieron, y ver las ventas en cada grupo. Esta comparación típicamente *no* resulta en una buena estimación 
de la cantidad que nos interesa, pues los que recibieron el anuncio
de *paid search* han mostrado más interés en hacer una compra que los que
no lo recibieron (por eso recibieron el anuncio!)

#### Ejemplo {-}

Veamos un ejercicio de simulación. Consideremos dos grupos de usuarios:
interesados y no interesados, que es una variable que no observamos. 
Suponemos que las ventas en cada grupo, independientemente de nuestras
acciones, son más altas para usuarios interesados que no interesados:

```{r}
compras_int_alto <- rpois(1000, 5)
compras_int_bajo <- rpois(1000, 1)
mean(compras_int_alto)
mean(compras_int_bajo)
```

Nótese que nosotros en principio no podemos hacer esta comparación,
pues interés no es una medida que tengamos disponible fácilmente.


Ahora supongamos ahora que las probabilidades de recibir el anuncio de *paid search* es más alto para los interesados que los no interesados (pues usuarios interesados hacen más búsquedas relevantes):

```{r}
ps_int_alto <- 0.04
ps_int_bajo <- 0.01
```

Y simulemos los datos que observaríamos. En primer lugar,
simulamos qué usuarios reciben o no anuncios:

```{r}
anuncio_int_alto <- rbinom(1000, 1, ps_int_alto) 
anuncio_int_bajo <-  rbinom(1000, 1, ps_int_bajo)
head(anuncio_int_alto)
```

Y juntamos los datos que observaríamos:

```{r}
datos <- data_frame(anuncio_ps= c(anuncio_int_alto, anuncio_int_bajo),
                    compras = c(compras_int_alto, compras_int_bajo))
datos
```


Si hacemos una comparación entre grupos, obtenemos:

```{r}
datos %>% group_by(anuncio_ps) %>% 
  summarise(media_compras = round(mean(compras), 2), n = n())
```
Y vemos que el grupo que recibió anuncio tiene más compras promedio
que el que no recibió anuncio. Sin embargo, en esta simulación
el anuncio no tiene ningún efecto.

Sin embargo, si distribuimos al azar la asignación del anuncio,

```{r}
datos %>% mutate(asigna = rbinom(2000, 1, 0.05)) %>% 
  group_by(asigna) %>% summarise(media_compras = round(mean(compras), 2), n = n())
```

Entonces obtenemos una comparación de "peras con peras"

### Aleatorización en experimentos.

Aunque intuitivamente está claro por qué en el ejemplo anterior podemos
obtener el análisis correcto cuando aleatorizamos el tratamiento (en este caso un anuncio), podemos ver algunos detalles matemáticos que explican por qué sucede.

Una manera fácil de entender esto es pensando en contrafactuales. Consideramos
las siguientes variables aleatorias:

- $Y (1)$ = compras de usario si recibe anuncio.
- $Y (0)$ = compras de usuario si no recibe anuncio.

Lo que típicamente nos interesa saber es
\begin{equation}
E\left[ Y(1)-  Y(0)\right ] = E[Y(1)]  - E[Y(0)]
(\#eq:difcausal)
\end{equation}

que podemos considerar como el efecto promedio del tratamiento (un anuncio, un cambio en el sitio, etc) sobre los usuarios.

En la práctica, consideramos una muestra de usuarios $Y_1,Y_2,\ldots, Y_n$. Algunos de estos recibirán el tratamiento y otros no, y escribimos $T_i=1$ si $i$ recibió el tratamiento y $T_i=0$ si no lo recibió. Las variables $Y_i$ que observamos
son:

- $Y_i = Y_i(1)$ si $T_i=1$
- $Y_i = Y_i(0)$ si $T_i=0$

La estimación directa de el valor esperado \@ref(eq:difcausal) la haríamos con
el promedio
$$\frac{1}{n}\sum_i (Y_i(1) - Y_i(0))$$
y notamos inmediatamente una dificultad: no observamos esta diferencia
para ninguno de los usuarios! Para cada usuario, observamos solamente una
de $Y_i(1)$ o $Y_i(0)$. Los datos, por ejemplo, se verían:

```{r}
datos_obs <- data_frame(i = c(1L,2L,3L,4L,5L), 
           `Y_i(1)` = c(NA, 5L, 3L, NA, NA),
           `Y_i(0)` = c(2L, NA, NA, 3L, 2L), 
            T=c(0L,1L,1L,0L,0L),
            Y_i=c(2L,5L,3L,3L,2L))
datos_obs
```

En cada caso, necesitamos el **contrafactual** de cada observación para poder
estimar el efecto promedio de nuestra intervención.

Nótese que viendo el lado derecho de \@ref(eq:probacola) podríamos intentar
hacer la *estimación estándar*, que consiste en tomar los promedios
de las columnas de los datos anteriores y promediar:
\begin{equation}
 \frac{1}{n_1} \sum_{T_i = 1} Y_i - \frac{1}{n_0} \sum_{T_i=0} Y_i.
(\#eq:estandar)
\end{equation}

donde promediamos los resultados de los tratados y restamos el promedio
de los no tratados.  En nuestro ejemplo, haríamos:

```{r}
mean.na <- function(x){ mean(x, na.rm = T)}
datos_obs %>%  
  summarise(media_tratados = mean.na(`Y_i(1)`),
            media_no_tratados = mean.na(`Y_i(0)`)) %>%
  mutate(diferencia = media_tratados - media_no_tratados)
```

Ahora consideremos por qué esta estimación puede tener sesgo alto.
El promedio $\frac{1}{n_1} \sum_{T_i = 1} Y_i$ es realmente una estimación
de 
$$E[Y|T = 1] = E[Y(1)|T=1]$$
Así que cuando la asignación del tratamiento está asociada a la variable
de respuesta $Y$, esta última cantidad no es necesariamente igual
a $E(Y(1))$. Explica en tus palabras por qué pasa esto (puedes comenzar
con el ejemplo de *paid search* que vimos arriba).

Igualmente, el promedio $\frac{1}{n_0} \sum_{T_i = 0} Y_i$ estima
la cantidad
$$E[Y|T = 0] = E[Y(0)|T=0]$$
que no necesariamente es igual a $E[Y(0)]$.

```{block2, type="resumen"}
El que a veces se llama el **problema fundamental de la inferencia causal** es
que nunca observamos los efectos causales directamente, pues nunca observamos
juntos el resultado más su contrafactual.
```


Con un experimento, sin embargo, podemos superar este problema.
Si **asignamos el tratamiento de manera aleatoria**, entonces
por definición $E(Y(0)) = E(Y(0)|T=0)$ y $E(Y(1)) = E(Y(1)|T=0)$ (T
es una variable aleatoria que no está correlacionada con ninguna otra variable),
y el estimador estándar \@ref(eq:estandar) es un estimador insesgado 
de la cantidad que nos interesa, que es \@ref(eq:difcausal).



## Costos de experimentación

Ahora supongamos que para simplificar nuestra vida, y tener resultados
sólidos, decidimos hacer un experimento A/B en nuestro sitio web. Decidimos
entonces, cada vez que un usuario pide una página x, tiramos un volado y decidimos
si le enseñamos la versión A y la versión B. Lo que hace este usuario en el resto
de su sesión estará registrado en los logs del sitio (o en una base de datos si
nuestra aplicación registra los resultados de interés). Podemos entonces, después
de tener un número apriopiado de usuarios en cada rama A y B, comparar los
dos grupos y tomar una decisión final acerca de qué versión nos conviene.

Las primeras objeciones que podemos hacer a esta decisión (y que muchos interesados
en el negocio seguramente plantearán):

- El experimento representa un riesgo al ingreso del sitio o el éxito del negocio. Si la modificación es contraproducente, entonces la duración del experimento representa pérdidas para el negocio. Por ejemplo, si decidimos hacer un experimento para saber si un anuncio está funcionando, en lugar de mostrar el anuncio a todos los usuarios que califican, solo una fracción lo recibirá. Esto representa pérdidas potenciales grandes. **Respuesta**: esto es cierto, en términos de ganancias a corto plazo. Pero hacer experimentación de manera más generalizada puede avanzar mejor el negocio a mediano y largo plazo, y dar más seguridad en la toma de decisiones.

- Hay también un costo técnico en establecer la infraestructura para hacer y analizar los experimentos adecuadamente.  **Respuesta**: esto es cierto.

- El camino de la experimentación muchas veces es contrario al pensamiento de los analistas de negocios/tomadores de decisiones, que a veces prefieren hacer análisis diseñados para entender el potencial de cambio *antes* de hacer ningún cambio. Por ejemplo encuestas, pruebas en focus groups, etc. **Respuesta**: el análisis ad-hoc es una herramienta poderosa, pero también muchas veces plagada de incertidumbre no siempre explícita (por ejemplo, muy dependiente del tipo de modelos que se consideran, o de los datos que se tienen a mano). Es posible combinar las dos aproximaciones.

En particular, los experimentos A/B (que pueden tener más de 2 opciones) tienen la debilidad de que

- Cuando hacemos experimentación, generalmente decidimos cuánto tiempo va a durar el experimento para tener tamaños de muestra adecuados. En algunos casos, las opciones son tan malas o tan buenas en relación a otras que esto es un desperdicio de dinero (podemos descartar una opción rápidamente por ser muy mala). 

- Desde el punto de vista del negocio, preferiríamos una solución donde cuanto más mala parece ser una opción, la exploramos menos para incurrir en menos pérdidas grandes. Sin embargo, queremos mantener algún nivel de exploración para poder encontrar mejores opciones a la que tenemos actualmente, especialmente cuando tenemos incertidumbre alta acerca de una opción.

## Algoritmos de tragamonedas

Los algoritmos de tragamonedas (multi-armed bandit algorithms) buscan 
dar soluciones a las deficiencias que acabamos de señalar en el esquema
de experimentación A/B. La idea básica es que para optimizar nuestro
sitio web (por ejemplo), necesitamos balancear dos tipos de acciones:

- **Exploratorias**: donde probamos nuevas opciones para ver cómo se desempeñan.
- **Explotadoras**: donde aplicamos las mejores opciones para tener buenos resultados de negocio.

Estas dos caras son indispensables para la optimización: no tiene mucho sentido
hacer ninguna de ellas si la otra no está presente (no queremos explotar opciones malas, ya sea porque no hemos explorado opciones, o porque desperdiciamos demasiado tiempo en explorar otras opciones).

```{block2, type="resumen"}
Una tragamonedas de $n$ brazos es un proceso aleatorio, donde:

- Escogemos uno de $n$ palancas de la tragamonedas
- Obtenemos una recompensa que depende de la palanca que escogimos.

¿Cómo debemos operar la máquina para lograr maximizar en algún
sentido nuestra recompensa?
```

En optimización de sitios web, las palancas son las distintas opciones
que podemos presentar a los usuarios, por ejemplo, 3 algoritmos de 
ordenación de resultados. Cada usuario es una jugada en la máquina
tragamonedas, y la recompensa es la métrica de desempeño que hayamos escogido
(por ejemplo, conversiones).


## Algoritmo epsilon-miope

Idea: casi siempre escoger la mejor opción. Pero de vez en cuando (con cierta
probabilidad) escogemos una opción al azar.

Sea $\epsilon > 0$, y supongamos que nuestra máquina tiene $n$
brazos. Cuando llega un usuario,

- Con probabilidad $1-\epsilon$ le presentamos la mejor opción que tenemos ahora
- Con probabilidad $\epsilon$ es escogemos al azar alguna de las $n$ opciones.

Implementamos primero un simulador del proceso que genera
recompensas (en general, esto es una caja negra):

```{r}
crear_maquina_poisson <- function(lambda){
  # utilizamos recompensas poisson con medias lambda
  n_brazos <- length(lambda)
  simular_maquina <- function(brazo){
      rpois(length(brazo), lambda = lambda[brazo])
  }
  simular_maquina
}
```

Probamos nuestro simulador y gráficamos los resultados para cada brazo:

```{r, fig.height = 3}
simular <- crear_maquina_poisson(lambda = c(1, 8, 10))
sim_recomp <- 
  data_frame(brazo = sample.int(3, 1000, replace = TRUE)) %>% 
  mutate(recompensa = simular(brazo)) %>%
  group_by(brazo) %>% mutate(media = mean(recompensa))
ggplot(sim_recomp, aes(x=recompensa)) + facet_wrap(~brazo) +
  geom_histogram(binwidth = 1.2) +
  geom_vline(aes(xintercept = media), colour = 'gray')
```


Ahora construimos nuestra función para el algoritmo e-miope

```{r}
crear_epsilon_miope <- function(epsilon, inicial = 1, sim_fun){
  n_brazos <- environment(sim_fun)$n_brazos
  conteos <- rep(0, n_brazos)
  recompensas <- vector("list", n_brazos)
  sumas <- rep(0, n_brazos)
  mejor <- inicial
  epsilon <- epsilon
  fun <- function(){
    if(runif(1) <= epsilon){
      #explorar
      brazo <- sample.int(n_brazos, 1)
    } else {
      #explotar
      brazo <- mejor
    }
    sim <- sim_fun(brazo)
    recompensas[[brazo]] <<- c(recompensas[[brazo]], sim)
    conteos[brazo] <<- conteos[brazo] + 1
    sumas[brazo] <<- sumas[brazo] + sim
    mejor <<- which.max(sumas /conteos)
  }
  fun
}
```





```{r}
set.seed(9322)
e_greedy <- crear_epsilon_miope(epsilon = 0.1, inicial = 1, sim_fun = simular)
e_ab_test <- crear_epsilon_miope(epsilon = 1.0, inicial = 1, sim_fun = simular)
tiempo <- 500
recompensa_prom_e <- vector("double", tiempo)
recompensa_prom_ab <- vector("double", tiempo)
recompensa_acum_e <- vector("double", tiempo)
recompensa_acum_ab <- vector("double", tiempo)

for(i in 1:tiempo){
  e_greedy()
  e_ab_test()
  sumas <- get("sumas", environment(e_greedy))
  conteos <- get("conteos", environment(e_greedy))
  recompensa_acum_e[i] <- sum(sumas)
  recompensa_prom_e[i] <- sum(sumas)/sum(conteos)
  if(i== 201){
    assign("epsilon", 0.0, environment(e_ab_test))
  }
  sumas <- get("sumas", environment(e_ab_test))
  conteos <- get("conteos", environment(e_ab_test))
  recompensa_acum_ab[i] <- sum(sumas)
  recompensa_prom_ab[i] <- sum(sumas)/sum(conteos) 
}
plot(recompensa_prom_e, type = "l", ylim = c(0,12)) 
abline(h = 10, col = 'red')
lines(recompensa_prom_ab, col = "orange")
```

Podemos graficar el acumulado:

```{r}
plot(recompensa_acum_e, type = "l") 
lines(recompensa_acum_ab, col = "orange")
```

Y ahora vemos claramente lo que ganamos por usar el algoritmo
de e-miope comparado con experimentos ab.

## Algoritmo softmax

```{r}
crear_softmax <- function(temperatura = 1, inicial = 1, sim_fun, recocido = F){
  n_brazos <- environment(sim_fun)$n_brazos
  conteos <- rep(0, n_brazos)
  recompensas <- vector("list", n_brazos)
  sumas <- rep(0, n_brazos)
  temperatura <- temperatura
  fun <- function(){
    if(recocido){
      temperatura <<- temperatura / log(t + 0.0001)
    }
    m <- max(sumas / temperatura)
    exp_sumas <- exp(sumas / temperatura - m)
    probs <- exp_sumas / sum(exp_sumas)
    brazo <- sample(1:n_brazos, 1, prob = probs)
    sim <- sim_fun(brazo)
    recompensas[[brazo]] <<- c(recompensas[[brazo]], sim)
    conteos[brazo] <<- conteos[brazo] + 1
    sumas[brazo] <<- sumas[brazo] + sim
    mejor <<- which.max(sumas /conteos)
  }
  fun
}
```


